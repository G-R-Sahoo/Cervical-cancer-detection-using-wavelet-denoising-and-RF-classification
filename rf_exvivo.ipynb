{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from pywt import wavedec, waverec\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import  accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams.update({\"font.size\": 12, \"font.weight\": 'bold', \"lines.linewidth\": 2, \"lines.markersize\": 7})\n",
    "os.chdir(r'C:\\Users\\gs582\\Dropbox\\IITK_Cervical\\Denoisig_RFclassification\\figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the functions here\n",
    "def wavelet_denoising(data, wave, lev, tsr, tm):\n",
    "\n",
    "\n",
    "    # Decompose the signal and calculate sparsity\n",
    "    cf = wavedec(data, wavelet = wave, level = lev)\n",
    "       \n",
    "    # Threshold the wavelet coefficients\n",
    "    for j in range(lev):\n",
    "        thrh = thvalue_vector(cf[-j-1][::], tsr)\n",
    "        cf[-j-1][::] = threshold_vector(x=cf[-j-1][::], thr=thrh, tm=tm)\n",
    "\n",
    "    # Reconstruct the denoised data\n",
    "    data_den = waverec(cf, wavelet = wave)\n",
    "\n",
    "    return data_den\n",
    "\n",
    "\n",
    "\n",
    "def extract_noise(data, wave, lev):\n",
    "    \"\"\" \n",
    "    Return noise present in the data. Noise is reconstructed from detail coefficeientsandthe denoised signal\n",
    "    is reconstructed using approximation coefficients.\n",
    "\n",
    "    decomposition level: decomposition level is decided using sparsity value of detail components.\n",
    "                         The  cutoff used for sparsity here is 0.03.\n",
    "\n",
    "    data_noise, data_denoised = extract_noise(data, wave)\n",
    "    \n",
    "    INPUT:\n",
    "        data: from which noise will be extracted.\n",
    "        wave: Mother wavelet function to be used for wavelet decomposition.\n",
    "\n",
    "    OUTPUT:\n",
    "        data_appx: Data reconstructed using only approximation coefficient at the last decomposition level.\n",
    "        data_det: Data reconstructed using detail components at all decomposition level.\n",
    "\n",
    "    Calculate sparsity of detail component at each level. \n",
    "    If sparsity at any level is > 0.5. then make it the final decomposition level.\n",
    "    Reconstruct only noise and signal using only detail component and approximation component.\n",
    "\n",
    "     \"\"\"\n",
    "    \n",
    "    # Find the length of the data\n",
    "    dat_len = len(data)\n",
    "\n",
    "    # Fins out if the number is even.\n",
    "    if (dat_len % 2) != 0:\n",
    "        raise ValueError('Data length should be even.')\n",
    "\n",
    "    cf = wavedec(data, wavelet = wave, level = lev)\n",
    "\n",
    "    cf_copy = copy.deepcopy(cf)\n",
    "\n",
    "    # Zero the approximation component and reconstruct only noise using the coefficients.\n",
    "    cf[0][::] = 0\n",
    "    #cf[-1][::] = 0\n",
    "    data_noise = waverec(cf, wavelet = wave)\n",
    "\n",
    "    # Zero the detail component and reconstrruct the denoised data using only approximation.\n",
    "    for j in range(lev):\n",
    "        cf_copy[-j-1][::] = 0\n",
    "\n",
    "    data_denoised = waverec(cf_copy, wavelet = wave)\n",
    "\n",
    "    return data_noise, data_denoised\n",
    "\n",
    "def data_wcfs(data, wave, lev):\n",
    "    \"\"\"Returns the approximation and detail of coefficients of the data at all the decomposition level using \"wavedec\".\n",
    "\n",
    "    Args:\n",
    "        data (Numpy Array): 1D vector of the reference data.\n",
    "        wave (String): Wavelet to be used for wavelet decomposition.\n",
    "        lev (Intiger): Deomposition level till which signal will be decomposed.\n",
    "\n",
    "    Returns:\n",
    "        cf (List): Returns a list of approximation and detail coefficients.\n",
    "    \"\"\"\n",
    "\n",
    "    app_ref, det_ref, cf = [], [], []\n",
    "    for i in range(1, lev+1):\n",
    "        c = wavedec(data=data, wavelet = wave, level=i)\n",
    "        exec(f'app_ref.append(c[0])')\n",
    "        exec(f'det_ref.append(c[1])')\n",
    "    cf.append(app_ref)\n",
    "    cf.append(det_ref)\n",
    "    return cf\n",
    "\n",
    "\n",
    "def Rf_classification(data, label, N_iter, CV):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        data (_type_): _description_\n",
    "        label (_type_): _description_\n",
    "        N_iter (_type_): _description_\n",
    "        CV (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # Define hyperfine parameters\n",
    "    n_estimator, max_depth = np.linspace(5, 100, 20, dtype=np.int64), np.linspace(2, 30, 15, dtype=np.int64)\n",
    "    max_feature = ['auto', 'sqrt', 'log2']\n",
    "    min_samples_split, min_samples_leaf = [2, 3, 5, 7, 10, 12, 15], [1, 2, 5, 7, 10, 12, 15]\n",
    "    \n",
    "    grid_param = {'n_estimators' : n_estimator, 'max_features' : max_feature,\n",
    "                   'max_depth' : max_depth, 'min_samples_split' : min_samples_split,\n",
    "                   'min_samples_leaf' : min_samples_leaf}\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=0)\n",
    "    clf = RandomizedSearchCV(estimator=clf, param_distributions=grid_param, n_iter=N_iter,\n",
    "                             cv=CV, verbose=2, n_jobs=-1)\n",
    "    \n",
    "    # Train the model\n",
    "    model = clf.fit(data, label)\n",
    "\n",
    "    return model\n",
    "\n",
    "def eval_metrics(y_v, y_pred):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        y_v (_type_): _description_\n",
    "        y_pred (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    conf_mat = confusion_matrix(y_v, y_pred)\n",
    "    fp = conf_mat.sum(axis = 0) - np.diag(conf_mat)\n",
    "    fn = conf_mat.sum(axis = 1) - np.diag(conf_mat)\n",
    "    tp = np.diag(conf_mat)\n",
    "    tn = conf_mat.sum() - tp + fn + fp\n",
    "    # Calculate accuracy, sensitivity, specificity, precisson and recall\n",
    "    Accuracy = (tp + tn)/(tp + tn + fp + fn)\n",
    "    Sensitivity = tp/(tp + fn)\n",
    "    Specificity = tn/(tn + fp)\n",
    "\n",
    "    precisson = precision_score(y_v, y_pred, average='micro')\n",
    "    recall = recall_score(y_v, y_pred, average='micro')\n",
    "    \n",
    "    return Accuracy, Sensitivity, Specificity, precisson, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and save the old data\n",
    "dat = np.load(r'C:\\Users\\gs582\\Dropbox\\IITK_Cervical\\Data\\Exvivo\\Nor_Pre_Can.npy')[:, :432]\n",
    "lab = np.load(r'C:\\Users\\gs582\\Dropbox\\IITK_Cervical\\Data\\Exvivo\\Label_NPC.npy')\n",
    "lambd = np.loadtxt(r'C:\\Users\\gs582\\Dropbox\\IITK_Cervical\\Data\\lambd.txt')\n",
    "# Delete the too noisy or corrupted data\n",
    "idx = [9, 10, 11, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 117, 118, 153, 155, 161, 174, 175, 176, 177,\n",
    "       181, 182, 183, 184, 185, 186, 187, 202, 203, 204, 207, 208, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 285]\n",
    "dat=np.delete(dat, idx, axis=0)\n",
    "lab = np.delete(lab, idx, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoise the data\n",
    "# Define wavelet function and decomposition level\n",
    "wave, dl = 'coif3', 3\n",
    "\n",
    "data_denoised, lev = np.empty((dat.shape), dtype=dat.dtype), np.empty((dat.shape[0]))\n",
    "for i in range(dat.shape[0]):\n",
    "    # Obtain the noisy and denoised data using the function extract_noise.\n",
    "    _, d2 = extract_noise(data=dat[i, :], wave=wave, lev=dl)\n",
    "    data_denoised[i, :] = d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area normalization of the data\n",
    "for i in range(dat.shape[0]):\n",
    "    dat[i, :] = np.divide(dat[i, :], np.trapz(dat[i, :], dx=1))\n",
    "    data_denoised[i, :] = np.divide(data_denoised[i, :], np.trapz(data_denoised[i, :], dx=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of noisy and denoised data\n",
    "i, j, k, alp, alp1 = 8, 148, 244, 0.7, 0.8\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4), sharex=False, sharey=False, constrained_layout=True, num=1, clear=True)\n",
    "\n",
    "ax[0].plot(lambd, dat[i, :]/np.max(dat[i, :]), 'b', alpha=alp1, label='Normal')\n",
    "ax[0].plot(lambd, dat[j, :]/np.max(dat[j, :]), 'm', alpha=alp1, label='Precancer')\n",
    "ax[0].plot(lambd, dat[k, :]/np.max(dat[k, :]), 'r', alpha=alp1, label='Cancer')\n",
    "lg = ax[0].legend(frameon=False, fontsize=10)\n",
    "for labels in lg.texts:\n",
    "    labels.set_alpha(alp)\n",
    "ax[0].set_xlim([lambd[0], lambd[431]])\n",
    "ax[0].set_xlabel('Wavelength (nm)', fontweight='bold', alpha=alp)\n",
    "ax[0].set_ylabel('Intensity (a.u.)', fontweight='bold', alpha=alp)\n",
    "ax[0].text(x=570, y=-0.39, s='(a)', fontsize=16)\n",
    "\n",
    "ax[1].plot(lambd, dat[i, :]/np.max(dat[i, :]), 'b', label='Noisy')\n",
    "ax[1].plot(lambd, data_denoised[i, :]/np.max(data_denoised[i, :]), 'r', label='Denoised')\n",
    "lg = ax[1].legend(frameon=False, fontsize=10)\n",
    "for labels in lg.texts:\n",
    "    labels.set_alpha(alp)\n",
    "ax[1].set_xlim([lambd[0], lambd[431]])\n",
    "ax[1].set_xlabel('Wavelength (nm)', fontweight='bold', alpha=alp)\n",
    "ax[1].set_ylabel('Intensity (a.u.)', fontweight='bold', alpha=alp)\n",
    "ax[1].text(x=570, y=-0.38, s='(b)', fontsize=16)\n",
    "# plt.savefig('int_den.png', dpi=400, bbox_inches='tight', transparent=True, pad_inches=0.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of noisy data\n",
    "# i, j, k, alp = 8, 148, 244, 0.7\n",
    "# plt.figure(figsize=(6, 4), dpi=100, constrained_layout=True)\n",
    "# plt.plot(lambd, dat[i, :]/np.max(dat[i, :]), 'b', label='Normal')\n",
    "# plt.plot(lambd, dat[j, :]/np.max(dat[j, :]), 'm', label='Precancer')\n",
    "# plt.plot(lambd, dat[k, :]/np.max(dat[k, :]), 'r', label='Cancer')\n",
    "# lg = plt.legend(frameon=False, fontsize=10)\n",
    "# for labels in lg.texts:\n",
    "#     labels.set_alpha(alp)\n",
    "# plt.xlim([lambd[0], lambd[431]])\n",
    "# plt.xlabel('Wavelength (nm)', fontweight='bold', alpha=alp)\n",
    "# plt.ylabel('Intensity (a.u.)', fontweight='bold', alpha=alp)\n",
    "# # plt.savefig('int.png', dpi=400, bbox_inches='tight', transparent=True, pad_inches=0.02)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot of noisy and denoised data\n",
    "# i, j, k, alp = 8, 148, 244, 0.7\n",
    "# plt.figure(figsize=(6, 4), dpi=100, constrained_layout=True)\n",
    "# plt.plot(lambd, dat[i, :]/np.max(dat[i, :]), 'b', label='Noisy')\n",
    "# plt.plot(lambd, data_denoised[i, :]/np.max(data_denoised[i, :]), 'b', label='Denoised')\n",
    "# # plt.plot(lambd, dat[j, :]/np.max(dat[j, :]), 'm', label='Noisy')\n",
    "# # plt.plot(lambd, data_denoised[j, :]/np.max(data_denoised[j, :]), 'm', label='Denoised')\n",
    "# # plt.plot(lambd, dat[k, :]/np.max(dat[k, :]), 'r', label='Noisy')\n",
    "# # plt.plot(lambd, data_denoised[k, :]/np.max(data_denoised[k, :]), 'r', label='Denoised')\n",
    "\n",
    "# lg = plt.legend(frameon=False, fontsize=10)\n",
    "# for labels in lg.texts:\n",
    "#     labels.set_alpha(alp)\n",
    "# plt.xlim([lambd[0], lambd[431]])\n",
    "# plt.xlabel('Wavelength (nm)', fontweight='bold', alpha=alp)\n",
    "# plt.ylabel('Intensity (a.u.)', fontweight='bold', alpha=alp)\n",
    "# # plt.savefig('den_int.png', dpi=400, bbox_inches='tight', transparent=True, pad_inches=0.02)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification of imbalanced noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing set\n",
    "xtun, xvun, ytun, yvun = train_test_split(dat, lab, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelun = Rf_classification(data=xtun, label=ytun, N_iter=500, CV=3)\n",
    "\n",
    "# Predict the class of test data set\n",
    "ypredun = modelun.predict(xvun)\n",
    "# Calculate evaluation matrices\n",
    "scoret, scorev = modelun.score(xtun, ytun), modelun.score(xvun, yvun)\n",
    "# Obtain the evaluation matrices\n",
    "accun, sensun, specun, precun, recalun = eval_metrics(y_pred=ypredun, y_v=yvun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelun.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Score : %0.2f' % (scoret*100))\n",
    "print('Testing Score : %0.2f' % (scorev*100))\n",
    "print('Accuracy :', accun)\n",
    "print('Sensitivity :', sensun)\n",
    "print('Specificity :', specun)\n",
    "print('Precission :', precun)\n",
    "print('Recall :', recalun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix and ROC\n",
    "# ROC plot for different classes\n",
    "pred_probun = modelun.predict_proba(xvun)\n",
    "\n",
    "fprun, tprun, roc_aucun = dict(), dict(), dict()\n",
    "n_cls = 3\n",
    "\n",
    "for i in range(n_cls):\n",
    "    fprun[i], tprun[i], _ = roc_curve(yvun, pred_probun[:, i], pos_label=i)\n",
    "    roc_aucun[i] = auc(fprun[i], tprun[i])\n",
    "\n",
    "fig = plt.figure(figsize=(8, 3), dpi=100, layout='constrained')\n",
    "gs = fig.add_gridspec(1, 2, hspace=0, wspace=0)\n",
    "ax = gs.subplots(sharex=False, sharey=False)\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(yvun, ypredun, display_labels=('Normal', 'Precancer', 'Cancer'), colorbar=False, ax=ax[0])\n",
    "# plt.set_yticks(rotation=90, verticalalignment='center')\n",
    "plt.setp(ax[0].get_yticklabels(), rotation=90, verticalalignment='center')\n",
    "# plt.savefig('conf_mat.png', dpi=400, bbox_inches='tight', pad_inches=0.02)\n",
    "\n",
    "ax[1].plot(fprun[0], tprun[0], '-b', label='Normal(Area = %0.2f)' %roc_aucun[0])\n",
    "ax[1].plot(fprun[1], tprun[1], '-m', label='Precancer(Area = %0.2f)' %roc_aucun[1])\n",
    "ax[1].plot(fprun[2], tprun[2], '-r', label='Cancer(Area = %0.2f)' %roc_aucun[2])\n",
    "ax[1].set_xlabel('False Positive Rate')\n",
    "ax[1].set_ylabel('True Positive rate')\n",
    "ax[1].set_xlim([-0.02, 1.02])\n",
    "ax[1].set_ylim([-0.02, 1.02])\n",
    "ax[1].legend(frameon=False, loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC plot\n",
    "alp, alp1 = 0.7, 0.8\n",
    "plt.figure(figsize=(6, 4), dpi=100, constrained_layout=True)\n",
    "plt.plot(fprun[0], tprun[0], '-b', alpha=alp1, label='Normal(Area = %0.2f)' %roc_aucun[0])\n",
    "plt.plot(fprun[1], tprun[1], '-m', alpha=alp1, label='Precancer(Area = %0.2f)' %roc_aucun[1])\n",
    "plt.plot(fprun[2], tprun[2], '-r', alpha=alp1, label='Cancer(Area = %0.2f)' %roc_aucun[2])\n",
    "plt.xlabel('False Positive Rate', fontweight='bold', alpha=alp)\n",
    "plt.ylabel('True Positive rate', fontweight='bold', alpha=alp)\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "lg = plt.legend(frameon=False, fontsize=8, loc='lower right')#, prop=dict(weight='light'))\n",
    "for labels in lg.texts:\n",
    "    labels.set_alpha(alp)\n",
    "# plt.savefig('roc_noisy.png', dpi=400, bbox_inches='tight', transparent=True, pad_inches=0.02)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "alp=0.7\n",
    "ConfusionMatrixDisplay.from_predictions(yvun, ypredun, display_labels=('Normal', 'Precancer', 'Cancer'), colorbar=False)\n",
    "plt.yticks(rotation=90, verticalalignment='center', alpha=0.6, fontweight='light', fontsize=10)\n",
    "plt.xticks(alpha=0.6, fontweight='light', fontsize=10)\n",
    "plt.xlabel('Predicted label', fontweight='bold', alpha=alp)\n",
    "plt.ylabel('True label', fontweight='bold', alpha=alp)\n",
    "# plt.savefig('conf_noisy.png', dpi=400, bbox_inches='tight', transparent=True, pad_inches=0.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification of balanced noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate balanced noisy data set using SMOTE\n",
    "datan, label1 = SMOTE().fit_resample(dat, lab)\n",
    "# Split the data into training and testing set\n",
    "xtn, xvn, ytn, yvn = train_test_split(datan, label1, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification of denoised data\n",
    "modeln = Rf_classification(data=xtn, label=ytn, N_iter=500, CV=3)\n",
    "\n",
    "# Predict the class of test data set\n",
    "ypredn = modeln.predict(xvn)\n",
    "# Calculate evaluation matrices\n",
    "scoret, scorev = modeln.score(xtn, ytn), modeln.score(xvn, yvn)\n",
    "# Obtain the evaluation matrices\n",
    "accurn, sensn, specn, precisn, recaln = eval_metrics(y_pred=ypredn, y_v=yvn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeln.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Score : %0.2f' % (scoret*100))\n",
    "print('Testing Score : %0.2f' % (scorev*100))\n",
    "print('Accuracy :', accurn)\n",
    "print('Sensitivity :', sensn)\n",
    "print('Specificity :', specn)\n",
    "print('Precission :', precisn)\n",
    "print('Recall :', recaln)\n",
    "# print('AUC_ROC : %0.2f' % auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix and ROC\n",
    "# ROC plot for different classes\n",
    "pred_probn = modeln.predict_proba(xvn)\n",
    "\n",
    "fprn, tprn, roc_aucn = dict(), dict(), dict()\n",
    "n_cls = 3\n",
    "\n",
    "for i in range(n_cls):\n",
    "    fprn[i], tprn[i], _ = roc_curve(yvn, pred_probn[:, i], pos_label=i)\n",
    "    roc_aucn[i] = auc(fprn[i], tprn[i])\n",
    "\n",
    "fig = plt.figure(figsize=(8, 3), dpi=100, layout='constrained')\n",
    "gs = fig.add_gridspec(1, 2, hspace=0, wspace=0)\n",
    "ax = gs.subplots(sharex=False, sharey=False)\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(yvn, ypredn, display_labels=('Normal', 'Precancer', 'Cancer'), colorbar=False, ax=ax[0])\n",
    "# plt.set_yticks(rotation=90, verticalalignment='center')\n",
    "plt.setp(ax[0].get_yticklabels(), rotation=90, verticalalignment='center')\n",
    "# plt.savefig('conf_mat.png', dpi=400, bbox_inches='tight', pad_inches=0.02)\n",
    "\n",
    "ax[1].plot(fprn[0], tprn[0], '-b', label='Normal(Area = %0.2f)' %roc_aucn[0])\n",
    "ax[1].plot(fprn[1], tprn[1], '-m', label='Precancer(Area = %0.2f)' %roc_aucn[1])\n",
    "ax[1].plot(fprn[2], tprn[2], '-r', label='Cancer(Area = %0.2f)' %roc_aucn[2])\n",
    "ax[1].set_xlabel('False Positive Rate')\n",
    "ax[1].set_ylabel('True Positive rate')\n",
    "ax[1].set_xlim([-0.02, 1.02])\n",
    "ax[1].set_ylim([-0.02, 1.02])\n",
    "ax[1].legend(frameon=False, fontsize=8, loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "alp=0.7\n",
    "ConfusionMatrixDisplay.from_predictions(yvn, ypredn, display_labels=('Normal', 'Precancer', 'Cancer'), colorbar=False)\n",
    "plt.yticks(rotation=90, verticalalignment='center', alpha=alp, fontweight='light', fontsize=10)\n",
    "plt.xticks(alpha=alp, fontweight='light', fontsize=10)\n",
    "plt.xlabel('Predicted label', fontweight='bold', alpha=alp)\n",
    "plt.ylabel('True label', fontweight='bold', alpha=alp)\n",
    "# plt.savefig('conf_noisy_bal.png', dpi=400, bbox_inches='tight', transparent=True, pad_inches=0.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC plot\n",
    "alp, alp1 = 0.7, 0.8\n",
    "plt.figure(figsize=(6, 4), dpi=100, constrained_layout=True)\n",
    "plt.plot(fprn[0], tprn[0], '-b', alpha=alp1, label='Normal(Area = %0.2f)' %roc_aucn[0])\n",
    "plt.plot(fprn[1], tprn[1], '-m', alpha=alp1, label='Precancer(Area = %0.2f)' %roc_aucn[1])\n",
    "plt.plot(fprn[2], tprn[2], '-r', alpha=alp1, label='Cancer(Area = %0.2f)' %roc_aucn[2])\n",
    "plt.xlabel('False Positive Rate', fontweight='bold', alpha=alp)\n",
    "plt.ylabel('True Positive rate', fontweight='bold', alpha=alp)\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "lg = plt.legend(frameon=False, fontsize=8, loc='lower right')#, prop=dict(weight='light'))\n",
    "for labels in lg.texts:\n",
    "    labels.set_alpha(alp)\n",
    "# plt.savefig('roc_noisy_bal.png', dpi=400, bbox_inches='tight', transparent=True, pad_inches=0.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.where(ytn==0)[0]), len(np.where(ytn==1)[0]), len(np.where(ytn==2)[0]))\n",
    "print(len(np.where(yvn==0)[0]), len(np.where(yvn==1)[0]), len(np.where(yvn==2)[0]))\n",
    "print(len(np.where(label1==0)[0]), len(np.where(label1==1)[0]), len(np.where(label1==2)[0]))\n",
    "print(len(label1), len(ytn), len(yvn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification of imbalanced denoised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing set\n",
    "xtd, xvd, ytd, yvd = train_test_split(data_denoised, lab, test_size=0.20, random_state=0)\n",
    "modeld = Rf_classification(data=xtd, label=ytd, N_iter=500, CV=3)\n",
    "\n",
    "# Predict the class of test data set\n",
    "ypredd = modeld.predict(xvd)\n",
    "# Calculate evaluation matrices\n",
    "scoret, scorev = modeld.score(xtd, ytd), modeld.score(xvd, yvd)\n",
    "# Obtain the evaluation matrices\n",
    "accuracy, sensitivity, specificity, precision, recal = eval_metrics(y_pred=ypredd, y_v=yvd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.where(ytd==0)[0]), len(np.where(ytd==1)[0]), len(np.where(ytd==2)[0]))\n",
    "print(len(np.where(yvd==0)[0]), len(np.where(yvd==1)[0]), len(np.where(yvd==2)[0]))\n",
    "print(len(np.where(lab==0)[0]), len(np.where(lab==1)[0]), len(np.where(lab==2)[0]))\n",
    "print(len(lab), len(ytd), len(yvd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeld.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, sensitivity, specificity, precision, recal = eval_metrics(y_pred=ypredd, y_v=yvd)\n",
    "print('Training Score : %0.2f' % (scoret*100))\n",
    "print('Testing Score : %0.2f' % (scorev*100))\n",
    "print('Accuracy :', accuracy)\n",
    "print('Sensitivity :', sensitivity)\n",
    "print('Specificity :', specificity)\n",
    "print('Precission :', precision)\n",
    "print('Recall :', recal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix and ROC\n",
    "# ROC plot for different classes\n",
    "pred_probd = modeld.predict_proba(xvd)\n",
    "\n",
    "fprd, tprd, roc_aucd = dict(), dict(), dict()\n",
    "n_cls = 3\n",
    "\n",
    "for i in range(n_cls):\n",
    "    fprd[i], tprd[i], _ = roc_curve(yvd, pred_probd[:, i], pos_label=i)\n",
    "    roc_aucd[i] = auc(fprd[i], tprd[i])\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4), dpi=100, layout='constrained')\n",
    "gs = fig.add_gridspec(1, 2, hspace=0, wspace=0)\n",
    "ax = gs.subplots(sharex=False, sharey=False)\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(yvd, ypredd, display_labels=('Normal', 'Precancer', 'Cancer'), colorbar=False, ax=ax[0])\n",
    "# plt.set_yticks(rotation=90, verticalalignment='center')\n",
    "plt.setp(ax[0].get_yticklabels(), rotation=90, verticalalignment='center')\n",
    "# plt.savefig('conf_mat.png', dpi=400, bbox_inches='tight', pad_inches=0.02)\n",
    "\n",
    "ax[1].plot(fprd[0], tprd[0], '-b', label='Normal(Area = %0.2f)' %roc_aucd[0])\n",
    "ax[1].plot(fprd[1], tprd[1], '-m', label='Precancer(Area = %0.2f)' %roc_aucd[1])\n",
    "ax[1].plot(fprd[2], tprd[2], '-r', label='Cancer(Area = %0.2f)' %roc_aucd[2])\n",
    "ax[1].set_xlabel('False Positive Rate')\n",
    "ax[1].set_ylabel('True Positive rate')\n",
    "ax[1].set_xlim([-0.02, 1.02])\n",
    "ax[1].set_ylim([-0.02, 1.02])\n",
    "ax[1].legend(frameon=False, loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC plot\n",
    "alp, alp1 = 0.7, 0.8\n",
    "plt.figure(figsize=(6, 4), dpi=100, constrained_layout=True)\n",
    "plt.plot(fprd[0], tprd[0], '-b', alpha=alp1, label='Normal(Area = %0.2f)' %roc_aucd[0])\n",
    "plt.plot(fprd[1], tprd[1], '-m', alpha=alp1, label='Precancer(Area = %0.2f)' %roc_aucd[1])\n",
    "plt.plot(fprd[2], tprd[2], '-r', alpha=alp1, label='Cancer(Area = %0.2f)' %roc_aucd[2])\n",
    "plt.xlabel('False Positive Rate', fontweight='bold', alpha=alp)\n",
    "plt.ylabel('True Positive rate', fontweight='bold', alpha=alp)\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "lg = plt.legend(frameon=False, fontsize=8, loc='lower right')#, prop=dict(weight='light'))\n",
    "for labels in lg.texts:\n",
    "    labels.set_alpha(alp)\n",
    "# plt.savefig('roc_den.png', dpi=400, bbox_inches='tight', transparent=True, pad_inches=0.02)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "alp=0.7\n",
    "ConfusionMatrixDisplay.from_predictions(yvd, ypredd, display_labels=('Normal', 'Precancer', 'Cancer'), colorbar=False)\n",
    "plt.yticks(rotation=90, verticalalignment='center', alpha=0.6, fontweight='light', fontsize=10)\n",
    "plt.xticks(alpha=0.6, fontweight='light', fontsize=10)\n",
    "plt.xlabel('Predicted label', fontweight='bold', alpha=alp)\n",
    "plt.ylabel('True label', fontweight='bold', alpha=alp)\n",
    "# plt.savefig('conf_den.png', dpi=400, bbox_inches='tight', transparent=True, pad_inches=0.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification of balanced denoised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate balanced denoised data set using SMOTE\n",
    "data_den, label2 = SMOTE().fit_resample(data_denoised, lab)\n",
    "# Split the data into training and testing set\n",
    "xtdb, xvdb, ytdb, yvdb = train_test_split(data_den, label2, test_size=0.20, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldb = Rf_classification(data=xtdb, label=ytdb, N_iter=500, CV=3)\n",
    "\n",
    "# Predict the class of test data set\n",
    "ypreddb = modeldb.predict(xvdb)\n",
    "# Calculate evaluation matrices\n",
    "scoret, scorev = modeldb.score(xtdb, ytdb), modeldb.score(xvdb, yvdb)\n",
    "# Obtain the evaluation matrices\n",
    "accuracy, sensitivity, specificity, precision, recal = eval_metrics(y_pred=ypreddb, y_v=yvdb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, sensitivity, specificity, precision, recal = eval_metrics(y_pred=ypreddb, y_v=yvdb)\n",
    "print('Training Score : %0.2f' % (scoret*100))\n",
    "print('Testing Score : %0.2f' % (scorev*100))\n",
    "print('Accuracy :', accuracy)\n",
    "print('Sensitivity :', sensitivity)\n",
    "print('Specificity :', specificity)\n",
    "print('Precission :', precision)\n",
    "print('Recall :', recal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix and ROC\n",
    "# ROC plot for different classes\n",
    "pred_probdb = modeldb.predict_proba(xvdb)\n",
    "\n",
    "fprdb, tprdb, roc_aucdb = dict(), dict(), dict()\n",
    "n_cls = 3\n",
    "\n",
    "for i in range(n_cls):\n",
    "    fprdb[i], tprdb[i], _ = roc_curve(yvdb, pred_probdb[:, i], pos_label=i)\n",
    "    roc_aucdb[i] = auc(fprdb[i], tprdb[i])\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4), dpi=100, layout='constrained')\n",
    "gs = fig.add_gridspec(1, 2, hspace=0, wspace=0)\n",
    "ax = gs.subplots(sharex=False, sharey=False)\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(yvdb, ypreddb, display_labels=('Normal', 'Precancer', 'Cancer'), colorbar=False, ax=ax[0])\n",
    "# plt.set_yticks(rotation=90, verticalalignment='center')\n",
    "plt.setp(ax[0].get_yticklabels(), rotation=90, verticalalignment='center')\n",
    "# plt.savefig('conf_mat.png', dpi=400, bbox_inches='tight', pad_inches=0.02)\n",
    "\n",
    "ax[1].plot(fprdb[0], tprdb[0], '-b', label='Normal(Area = %0.2f)' %roc_aucdb[0])\n",
    "ax[1].plot(fprdb[1], tprdb[1], '-m', label='Precancer(Area = %0.2f)' %roc_aucdb[1])\n",
    "ax[1].plot(fprdb[2], tprdb[2], '-r', label='Cancer(Area = %0.2f)' %roc_aucdb[2])\n",
    "ax[1].set_xlabel('False Positive Rate')\n",
    "ax[1].set_ylabel('True Positive rate')\n",
    "ax[1].set_xlim([-0.02, 1.02])\n",
    "ax[1].set_ylim([-0.02, 1.02])\n",
    "ax[1].legend(frameon=False, loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "alp=0.7\n",
    "ConfusionMatrixDisplay.from_predictions(yvdb, ypreddb, display_labels=('Normal', 'Precancer', 'Cancer'), colorbar=False)\n",
    "plt.yticks(rotation=90, verticalalignment='center', alpha=0.6, fontweight='light', fontsize=10)\n",
    "plt.xticks(alpha=0.6, fontweight='light', fontsize=10)\n",
    "plt.xlabel('Predicted label', fontweight='bold', alpha=alp)\n",
    "plt.ylabel('True label', fontweight='bold', alpha=alp)\n",
    "# plt.savefig('conf_den_bal.png', dpi=400, bbox_inches='tight', transparent=True, pad_inches=0.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC plot\n",
    "alp, alp1 = 0.7, 0.8\n",
    "plt.figure(figsize=(6, 4), dpi=100, constrained_layout=True)\n",
    "plt.plot(fprdb[0], tprdb[0], '-b', alpha=alp1, label='Normal(Area = %0.2f)' %roc_aucdb[0])\n",
    "plt.plot(fprdb[1], tprdb[1], '-m', alpha=alp1, label='Precancer(Area = %0.2f)' %roc_aucdb[1])\n",
    "plt.plot(fprdb[2], tprdb[2], '-r', alpha=alp1, label='Cancer(Area = %0.2f)' %roc_aucdb[2])\n",
    "plt.xlabel('False Positive Rate', fontweight='bold', alpha=alp)\n",
    "plt.ylabel('True Positive rate', fontweight='bold', alpha=alp)\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "lg = plt.legend(frameon=False, fontsize=8, loc='lower right')#, prop=dict(weight='light'))\n",
    "for labels in lg.texts:\n",
    "    labels.set_alpha(alp)\n",
    "# plt.savefig('roc_den_bal.png', dpi=400, bbox_inches='tight', transparent=True, pad_inches=0.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of all the confusion matrix\n",
    "alp=0.8\n",
    "fig, ax = plt.subplots(1, 4, figsize=(16, 4), sharex=False, sharey=False, constrained_layout=True, num=1, clear=True)\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(yvun, ypredun, display_labels=('Normal', 'Precancer', 'Cancer'), colorbar=False, ax=ax[0])\n",
    "plt.setp(ax[0].get_yticklabels(), rotation=90, verticalalignment='center', fontweight='light', alpha=alp, fontsize=12)\n",
    "plt.setp(ax[0].get_xticklabels(), verticalalignment='center', fontweight='light', alpha=alp, fontsize=12)\n",
    "ax[0].set_xlabel('Predicted label', fontsize=14, fontweight='bold', alpha=alp)\n",
    "ax[0].set_ylabel('True label', fontsize=14, fontweight='bold', alpha=alp)\n",
    "ax[0].text(x=0.85, y=3.1, s='(a)', fontsize=16)\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(yvd, ypredd, display_labels=('Normal', 'Precancer', 'Cancer'), colorbar=False, ax=ax[1])\n",
    "plt.setp(ax[1].get_yticklabels(), rotation=90, verticalalignment='center', fontweight='light', alpha=alp, fontsize=12)\n",
    "plt.setp(ax[1].get_xticklabels(), verticalalignment='center', fontweight='light', alpha=alp, fontsize=12)\n",
    "ax[1].set_xlabel('Predicted label', fontsize=14, fontweight='bold', alpha=alp)\n",
    "ax[1].set_ylabel('True label', fontsize=14, fontweight='bold', alpha=alp)\n",
    "ax[1].text(x=0.85, y=3.1, s='(b)', fontsize=16)\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(yvn, ypredn, display_labels=('Normal', 'Precancer', 'Cancer'), colorbar=False, ax=ax[2])\n",
    "plt.setp(ax[2].get_yticklabels(), rotation=90, verticalalignment='center', fontweight='light', alpha=alp, fontsize=12)\n",
    "plt.setp(ax[2].get_xticklabels(), verticalalignment='center', fontweight='light', alpha=alp, fontsize=12)\n",
    "ax[2].set_xlabel('Predicted label', fontsize=14, fontweight='bold', alpha=alp)\n",
    "ax[2].set_ylabel('True label', fontsize=14, fontweight='bold', alpha=alp)\n",
    "ax[2].text(x=0.85, y=3.1, s='(c)', fontsize=16)\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(yvdb, ypreddb, display_labels=('Normal', 'Precancer', 'Cancer'), colorbar=False, ax=ax[3])\n",
    "plt.setp(ax[3].get_yticklabels(), rotation=90, verticalalignment='center', fontweight='light', alpha=alp, fontsize=12)\n",
    "plt.setp(ax[3].get_xticklabels(), verticalalignment='center', fontweight='light', alpha=alp, fontsize=12)\n",
    "ax[3].set_xlabel('Predicted label', fontsize=14, fontweight='bold', alpha=alp)\n",
    "ax[3].set_ylabel('True label', fontsize=14, fontweight='bold', alpha=alp)\n",
    "ax[3].text(x=0.85, y=3.1, s='(d)', fontsize=16)\n",
    "\n",
    "# plt.savefig('conf_all.png', dpi=400, bbox_inches='tight', transparent=True, pad_inches=0.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roc plot of all the categories\n",
    "alp, alp1 = 0.8, 0.9\n",
    "fig, ax = plt.subplots(1, 4, figsize=(22, 4), sharex=False, sharey=False, constrained_layout=True, num=1, clear=True)\n",
    "\n",
    "ax[0].plot(fprun[0], tprun[0], '-b', alpha=alp1, label='Normal(Area = %0.2f)' %roc_aucun[0])\n",
    "ax[0].plot(fprun[1], tprun[1], '-m', alpha=alp1, label='Precancer(Area = %0.2f)' %roc_aucun[1])\n",
    "ax[0].plot(fprun[2], tprun[2], '-r', alpha=alp1, label='Cancer(Area = %0.2f)' %roc_aucun[2])\n",
    "ax[0].set_xlabel('False Positive Rate', fontweight='bold', alpha=alp)\n",
    "ax[0].set_ylabel('True Positive rate', fontsize=14, fontweight='bold', alpha=alp)\n",
    "ax[0].set_xlim([-0.01, 1.01])\n",
    "ax[0].set_ylim([-0.01, 1.01])\n",
    "lg = ax[0].legend(frameon=False, fontsize=14, loc='lower right')#, prop=dict(weight='light'))\n",
    "for labels in lg.texts:\n",
    "    labels.set_alpha(alp)\n",
    "ax[0].text(x=0.5, y=-0.24, s='(a)', fontsize=16)\n",
    "\n",
    "ax[1].plot(fprd[0], tprd[0], '-b', alpha=alp1, label='Normal(Area = %0.2f)' %roc_aucd[0])\n",
    "ax[1].plot(fprd[1], tprd[1], '-m', alpha=alp1, label='Precancer(Area = %0.2f)' %roc_aucd[1])\n",
    "ax[1].plot(fprd[2], tprd[2], '-r', alpha=alp1, label='Cancer(Area = %0.2f)' %roc_aucd[2])\n",
    "ax[1].set_xlabel('False Positive Rate', fontsize=14, fontweight='bold', alpha=alp)\n",
    "ax[1].set_ylabel('True Positive rate', fontsize=14, fontweight='bold', alpha=alp)\n",
    "ax[1].set_xlim([-0.01, 1.01])\n",
    "ax[1].set_ylim([-0.01, 1.01])\n",
    "lg = ax[1].legend(frameon=False, fontsize=14, loc='lower right')#, prop=dict(weight='light'))\n",
    "for labels in lg.texts:\n",
    "    labels.set_alpha(alp)\n",
    "ax[1].text(x=0.5, y=-0.24, s='(b)', fontsize=16)\n",
    "\n",
    "ax[2].plot(fprn[0], tprn[0], '-b', alpha=alp1, label='Normal(Area = %0.2f)' %roc_aucn[0])\n",
    "ax[2].plot(fprn[1], tprn[1], '-m', alpha=alp1, label='Precancer(Area = %0.2f)' %roc_aucn[1])\n",
    "ax[2].plot(fprn[2], tprn[2], '-r', alpha=alp1, label='Cancer(Area = %0.2f)' %roc_aucn[2])\n",
    "ax[2].set_xlabel('False Positive Rate', fontsize=14, fontweight='bold', alpha=alp)\n",
    "ax[2].set_ylabel('True Positive rate', fontsize=14, fontweight='bold', alpha=alp)\n",
    "ax[2].set_xlim([-0.01, 1.01])\n",
    "ax[2].set_ylim([-0.01, 1.01])\n",
    "lg = ax[2].legend(frameon=False, fontsize=14, loc='lower right')#, prop=dict(weight='light'))\n",
    "for labels in lg.texts:\n",
    "    labels.set_alpha(alp)\n",
    "ax[2].text(x=0.5, y=-0.24, s='(c)', fontsize=16)\n",
    "\n",
    "ax[3].plot(fprdb[0], tprdb[0], '-b', alpha=alp1, label='Normal(Area = %0.2f)' %roc_aucdb[0])\n",
    "ax[3].plot(fprdb[1], tprdb[1], '-m', alpha=alp1, label='Precancer(Area = %0.2f)' %roc_aucdb[1])\n",
    "ax[3].plot(fprdb[2], tprdb[2], '-r', alpha=alp1, label='Cancer(Area = %0.2f)' %roc_aucdb[2])\n",
    "ax[3].set_xlabel('False Positive Rate', fontsize=14, fontweight='bold', alpha=alp)\n",
    "ax[3].set_ylabel('True Positive rate', fontsize=14, fontweight='bold', alpha=alp)\n",
    "ax[3].set_xlim([-0.01, 1.01])\n",
    "ax[3].set_ylim([-0.01, 1.01])\n",
    "lg = ax[3].legend(frameon=False, fontsize=14, loc='lower right')#, prop=dict(weight='light'))\n",
    "for labels in lg.texts:\n",
    "    labels.set_alpha(alp)\n",
    "ax[3].text(x=0.5, y=-0.24, s='(d)', fontsize=16)\n",
    "# plt.savefig('roc_all.png', dpi=400, bbox_inches='tight', transparent=True, pad_inches=0.02)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
